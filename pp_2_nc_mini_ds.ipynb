{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import os\n",
    "import shutil\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3hrly\n",
      "5850\n",
      "5850\n",
      "\n",
      "\n",
      "6hrly\n",
      "5850\n",
      "1447\n",
      "\n",
      "\n",
      "daily\n",
      "5850\n",
      "5850\n",
      "\n",
      "\n",
      "hourly\n",
      "5850\n",
      "5850\n",
      "\n",
      "\n",
      "monthly\n",
      "1920\n",
      "1920\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dirs = ['3hrly',  '6hrly',  'daily'  ,'hourly' ,'monthly']\n",
    "for dir in dirs:\n",
    "    print(dir)\n",
    "    ! ls /data/cssp-china/mini-dataset-24-01-19/20CR/{dir} | wc -l\n",
    "    ! ls /data/cssp-china/mini-dataset-24-01-19/nc/{dir} | wc -l\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_DIR = '6hrly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DATA_PATH=f\"/data/cssp-china/mini-dataset-24-01-19/20CR/{SUB_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apepda.pb51150.pp\n",
      "apepda.pb511f0.pp\n",
      "apepda.pb511p0.pp\n",
      "apepda.pb51240.pp\n",
      "apepda.pb512e0.pp\n",
      "apepda.pb512o0.pp\n",
      "apepda.pb51360.pp\n",
      "apepda.pb513g0.pp\n",
      "apepda.pb513q0.pp\n",
      "apepda.pb51450.pp\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls {SAMPLE_DATA_PATH} | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(SAMPLE_DATA_PATH, f) for f in sorted(os.listdir(SAMPLE_DATA_PATH)) if f[-3:]=='.pp' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_path = files[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIR =  f\"/data/cssp-china/mini-dataset-24-01-19/20CR/{SUB_DIR}\"\n",
    "OUT_DIR = f\"/data/cssp-china/mini-dataset-24-01-19/nc/{SUB_DIR}\"\n",
    "!mkdir -p {OUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paths(old='/data/cssp-china/mini-dataset-24-01-19/20CR/6hrly/apepda.pb51150.pp', new='/data/cssp-china/mini-dataset-24-01-19/nc/6hrly/apepda.pb51150.nc')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Paths = namedtuple('Paths',['old','new'])\n",
    "def get_new_and_old_path(path):\n",
    "    filename = os.path.basename(path)\n",
    "    new_filename = filename[:-2] + 'nc' if filename[-2:].lower() == 'pp' else filename + '.nc'\n",
    "    new_path = os.path.join(OUT_DIR, new_filename)\n",
    "    return Paths(path, new_path)\n",
    "\n",
    "eg_path = get_new_and_old_path(files[0] )\n",
    "eg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def not_converted(paths):\n",
    "    return not os.path.exists(paths.new)\n",
    "\n",
    "not_converted(eg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = eg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paths(old='/data/cssp-china/mini-dataset-24-01-19/20CR/6hrly/apepda.pb51150.pp', new='/data/cssp-china/mini-dataset-24-01-19/nc/6hrly/apepda.pb51150.nc')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import dask\n",
    "# def local_convert(paths):\n",
    "#     tmp_path = '/tmp/'+os.path.basename(paths.old)\n",
    "#     tmp_path_new = '/tmp/'+os.path.basename(paths.new)\n",
    "#     shutil.copy(paths.old, tmp_path)\n",
    "    \n",
    "#     with dask.config.set(scheduler='single-threaded'):\n",
    "#         precipitation_flux\n",
    "#         iris.fileformats.netcdf.save(cube, tmp_path_new, zlib=True, complevel=2)\n",
    "    \n",
    "    \n",
    "#     shutil.copy(tmp_path_new, paths.new)\n",
    "    \n",
    "#     try:\n",
    "#         os.remove(tmp_path_new)\n",
    "#     except Exception:\n",
    "#         print(f\"could not delete {tmp_path_new}\")\n",
    "              \n",
    "#     try:\n",
    "#         os.remove(tmp_path)\n",
    "#     except Exception:\n",
    "#         print(f\"could not delete {tmp_path}\")\n",
    "\n",
    "#     return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def convert(paths):\n",
    "    with dask.config.set(scheduler='single-threaded'):\n",
    "        cubes = iris.load(paths.old)\n",
    "        Path(os.path.dirname(paths.new)).mkdir(parents=True, exist_ok=True)\n",
    "        iris.fileformats.netcdf.save(cubes, paths.new, zlib=False)\n",
    "        return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.99 s, sys: 1.27 s, total: 9.26 s\n",
      "Wall time: 14.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Paths(old='/data/cssp-china/mini-dataset-24-01-19/20CR/6hrly/apepda.pb51150.pp', new='/data/cssp-china/mini-dataset-24-01-19/nc/6hrly/apepda.pb51150.nc')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "convert(eg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 149M Jan 26 15:15 /data/cssp-china/mini-dataset-24-01-19/20CR/6hrly/apepda.pb51150.pp\n",
      "-rwxrwxrwx 1 root root 312M Feb 10 13:27 /data/cssp-china/mini-dataset-24-01-19/nc/6hrly/apepda.pb51150.nc\n"
     ]
    }
   ],
   "source": [
    "! ls -lh {eg_path.new} {eg_path.old}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "import dask\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask import bag as db\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from functools import partial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<convert..., npartitions=101>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion = db.from_sequence(files).map(get_new_and_old_path).filter(not_converted).map(convert)\n",
    "conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: pip install jupyter-server-proxy\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:   tcp://10.244.0.48:40469\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7dd31b6aae476180ecb47e666fe771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-9e73befa-4cbd-11ea-80cf-3f98550bcf77\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.244.0.48:40469</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/tam203/proxy/8787/status' target='_blank'>/user/tam203/proxy/8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.244.0.48:40469' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register tcp://10.244.0.50:43345\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.50:43345\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.49:44239\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.49:44239\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.51:46857\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.51:46857\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.27:34877\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.27:34877\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.26:43517\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.26:43517\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.28:41663\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.28:41663\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.52:44587\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.52:44587\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.29:44169\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.18:40029\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.17:45711\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.29:44169\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.18:40029\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.17:45711\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.16:34985\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.16:34985\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.19:35399\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.19:35399\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.30:33875\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.30:33875\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.31:38887\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.31:38887\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.53:38911\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.53:38911\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.54:42965\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.54:42965\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.20:36095\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.20:36095\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.55:34509\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.55:34509\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.21:35357\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.21:35357\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.32:46103\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.32:46103\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.33:46633\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.33:46633\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.22:43271\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.22:43271\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.56:42509\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.56:42509\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.23:45067\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.23:45067\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.0.57:39549\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.57:39549\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.24:43935\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.24:43935\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.9.34:44795\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.34:44795\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.244.1.25:36443\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.25:36443\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "cluster = KubeCluster()\n",
    "cluster.scale_up(30)\n",
    "display(cluster)\n",
    "# Connect dask to the cluster\n",
    "client = distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_convert = db.from_sequence(files).map(get_new_and_old_path).filter(not_converted).to_converte()\n",
    "to_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove worker tcp://10.244.9.32:46103\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.32:46103\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.9.26:43517\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.26:43517\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.9.30:33875\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.30:33875\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.9.33:46633\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.33:46633\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.9.29:44169\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.29:44169\n",
      "distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.9.28:41663\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.28:41663\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.0.49:44239\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.49:44239\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.0.51:46857\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.51:46857\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.0.52:44587\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.52:44587\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.0.54:42965\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.54:42965\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.0.55:34509\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.55:34509\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.0.56:42509\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.56:42509\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.0.50:43345\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.50:43345\n",
      "distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.244.9.34:44795\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.34:44795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 565 ms, total: 4.86 s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Paths(old='/data/cssp-china/mini-dataset-24-01-19/20CR/6hrly/apepda.pbg3a10.pp', new='/data/cssp-china/mini-dataset-24-01-19/nc/6hrly/apepda.pbg3a10.nc')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with ProgressBar():\n",
    "    converted = conversion.compute()\n",
    "converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datasci)",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
